{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure to also output the intermediary steps\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Cleaning Dirty Data: the Data Encoding Bot\n",
    "\n",
    "[2IMM00] Seminar Data Mining\n",
    "<br>\n",
    "Angelo Majoor - 1030843\n",
    "<br>\n",
    "A.R.Majoor@student.tue.nl\n",
    "\n",
    "Supervisor: dr. ir. J. (Joaquin) Vanschoren\n",
    "\n",
    "Eindhoven University of Technology\n",
    "<br>\n",
    "Department of Mathematics and Computer Science\n",
    "<br>\n",
    "Data Mining Research Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all relevant libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import openml as oml\n",
    "oml.config.apikey = '2d4efc0fbf4c75a890be14297c5ec1e4'\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The three different steps\n",
    "\n",
    "As stated in the report, the process of creating the data encoding bot consists of three different steps:\n",
    "\n",
    " - Auto-detecting data types per feature (column)\n",
    " - Auto-detecting numeric, ordinal, categorical (integer) features\n",
    " - Auto-selecting encoding techniques for all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "6\n",
      "11\n",
      "12\n",
      "14\n",
      "15\n",
      "16\n",
      "18\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "28\n",
      "29\n",
      "31\n",
      "32\n",
      "36\n",
      "37\n",
      "41\n",
      "43\n",
      "45\n",
      "49\n",
      "53\n",
      "58\n",
      "219\n",
      "2074\n",
      "2079\n",
      "3021\n",
      "3022\n",
      "3481\n",
      "3485\n",
      "3492\n",
      "3493\n",
      "3494\n",
      "3510\n",
      "3512\n",
      "3543\n",
      "3549\n",
      "3560\n",
      "3561\n",
      "3567\n",
      "3573\n",
      "3889\n",
      "3891\n",
      "3896\n",
      "3899\n",
      "3902\n",
      "3903\n",
      "3904\n",
      "3913\n",
      "3917\n",
      "3918\n",
      "3946\n",
      "3948\n",
      "3954\n",
      "7592\n",
      "9914\n",
      "9946\n",
      "9950\n",
      "9952\n",
      "9954\n",
      "9955\n",
      "9956\n",
      "9957\n",
      "9960\n",
      "9964\n",
      "9967\n",
      "9968\n",
      "9970\n",
      "9971\n",
      "9976\n",
      "9977\n",
      "9978\n",
      "9979\n",
      "9980\n",
      "9981\n",
      "9983\n",
      "9985\n",
      "9986\n",
      "10093\n",
      "10101\n",
      "14964\n",
      "14965\n",
      "14966\n",
      "14967\n",
      "14968\n",
      "14969\n",
      "14970\n",
      "34536\n",
      "34537\n",
      "34538\n",
      "34539\n",
      "125920\n",
      "125921\n",
      "125922\n",
      "125923\n",
      "146195\n",
      "146606\n",
      "146607\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.]\n",
      "0\n",
      "[ 1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.]\n",
      "0\n",
      "[ 1.  1.  1.  1.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.]\n",
      "0\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "  1.  1.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.]\n",
      "0\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "  1.  1.  1.  1.  1.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Load the OpenML100 data set\n",
    "benchmark_suite = oml.study.get_study('OpenML100','tasks')\n",
    "\n",
    "list_task_ids = []\n",
    "\n",
    "# Find all task_ids\n",
    "for task_id in benchmark_suite.tasks:\n",
    "    list_task_ids.append(task_id)\n",
    "    print(task_id)\n",
    "\n",
    "#list_task_ids\n",
    "\n",
    "task = oml.tasks.get_task(3)\n",
    "\n",
    "X, y = task.get_X_and_y()\n",
    "for i in range (0,5):\n",
    "    print (X[i])\n",
    "    print (y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Auto-Detecting Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angelomajoor/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date                       object\n",
       "time                       object\n",
       "seconds                     int64\n",
       "total_consumption         float64\n",
       "total_production          float64\n",
       "solar_production           object\n",
       "total_solar_production    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 100, Float64: 0, Int64: 0, String: 0\n",
      "Date: 0, Float64: 0, Int64: 0, String: 100\n",
      "Date: 0, Float64: 0, Int64: 76, String: 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['date', 'string', 'int64', 'float64', 'float64', 'int64', 'float64']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_energy = pd.read_csv(\"energy_train_copy.csv\")\n",
    "#raw_energy.head()\n",
    "raw_energy.dtypes\n",
    "\n",
    "raw_weather = pd.read_csv(\"weather_train_copy.csv\")\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "#raw_data = pd.read_csv(\"ENTER_YOUR_CSV_FILE_NAME_HERE\")\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "# Function to automatically infer data data for a specific feature that has the standard 'object' data type\n",
    "# Data types that we want to infer: boolean, date, float, integer, string\n",
    "# Input: Pandas Dataframe consisting of one single feature (so n*1 in size)\n",
    "# Output: Data type of the feature (in string format)\n",
    "def autoInferObjects(raw_data_feature):\n",
    "    dataType = \"\"\n",
    "    types = [\"date\",\"float64\",\"int64\",\"string\"] #Data types\n",
    "    weights = [0,0,0,0] # Weights corresponding to the data types\n",
    "    numberOfIndices = 100 # Number of different values to check in a feature\n",
    "    \n",
    "    featureLength = len(raw_data_feature) #Number of rows in the feature\n",
    "    \n",
    "    randomIndices = random.sample(range(0,featureLength), min(numberOfIndices,featureLength)) #Array of random indices\n",
    "    \n",
    "    # If the feature only contains two different unique values, then infer it as boolean\n",
    "    if len(pd.unique(raw_data_feature)) == 2:\n",
    "        dataType = \"bool\"\n",
    "    else:\n",
    "        for i in randomIndices:\n",
    "            try:\n",
    "                if ((raw_data_feature[i][2:3] == ('-' or '/') and raw_data_feature[i][5:6] == ('-' or '/')) or \n",
    "                (raw_data_feature[i][4:5] == ('-' or '/') and raw_data_feature[i][7:8] == ('-' or '/'))):\n",
    "                    weights[0] += 1 #Date\n",
    "                else:\n",
    "                    weights[3] += 1 #String\n",
    "                    #print(\"Try on Date: {}, data type: {}, index: {}\".format(raw_data_feature[i],type(raw_data_feature[i]),i))\n",
    "            except (TypeError,ValueError,IndexError):\n",
    "                try:\n",
    "                    int(raw_data_feature[i])\n",
    "                    if ('.' in str(raw_data_feature[i])):\n",
    "                        weights[1] += 1 #Float\n",
    "                    else:\n",
    "                        weights[2] += 1 #Integer\n",
    "                except (TypeError,ValueError,IndexError):\n",
    "                    weights[3] += 1 #String\n",
    "                    #print(\"Try on Int: {}, data type: {}, index: {}\".format(raw_data_feature[i],type(raw_data_feature[i]),i))\n",
    "    \n",
    "    print (\"Date: {}, Float64: {}, Int64: {}, String: {}\".format(weights[0],weights[1],weights[2],weights[3]))\n",
    "    dataType = types[weights.index(max(weights))]\n",
    "    return dataType\n",
    "\n",
    "\n",
    "# Function to automatically infer data types for every single feature in a raw data set\n",
    "# Input: Pandas Dataframe created directly from the raw data with the pd.read_csv function\n",
    "# Output: List of data types, one data type for each feature\n",
    "def autoDetectDataTypes(raw_data):\n",
    "    result = []\n",
    "    \n",
    "    for column in raw_data:\n",
    "        if raw_data.dtypes[column] == \"object\":\n",
    "            result.append(autoInferObjects(raw_data[column]))\n",
    "            # Auto-infer in step 1\n",
    "        elif raw_data.dtypes[column] == \"int64\":\n",
    "            result.append(\"int64\")\n",
    "            # Go to step 2\n",
    "        else:\n",
    "            # The only remaining data type is 'float64', which needs no special treatment\n",
    "            result.append(\"float64\")\n",
    "        \n",
    "    return result\n",
    "\n",
    "autoDetectDataTypes(raw_energy)\n",
    "\n",
    "#s = raw_energy['solar_production']\n",
    "#s\n",
    "\n",
    "#autoInferObjects(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
